{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5814928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iport packages\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import pixellib\n",
    "from pixellib.torchbackend.instance import instanceSegmentation\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f251c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input folder and add full path\n",
    "image_filename = 'data/'\n",
    "img = load_img(image_filename)\n",
    "image_data = img_to_array(img)\n",
    "images_data = np.expand_dims(image_data, axis=0)\n",
    "datagen = ImageDataGenerator(width_shift_range=0.2)\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 5\n",
    "columns = 4\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590de660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation  \n",
    "datagen = ImageDataGenerator(height_shift_range=0.2)\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 5\n",
    "columns = 4\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation for horizontal_flip\n",
    "datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):        \n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation for vertical_flip\n",
    "datagen = ImageDataGenerator(vertical_flip=True)\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 2\n",
    "columns = 2\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56aadb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation for rotation\n",
    "datagen = ImageDataGenerator(rotation_range=50)\n",
    "train_generator = datagen.flow(images_data)\n",
    "rows = 5\n",
    "columns = 4\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ed756",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation for brightness\n",
    "datagen = ImageDataGenerator(brightness_range=[0.15,2.0])\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 5\n",
    "columns = 4\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation for zoom\n",
    "datagen = ImageDataGenerator(zoom_range=[5,0.5])\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 5\n",
    "columns = 4\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augumentation for zoom\n",
    "datagen = ImageDataGenerator(zoom_range=[5,0.5])\n",
    "train_generator = datagen.flow(images_data, batch_size=1)\n",
    "rows = 5\n",
    "columns = 4\n",
    "fig, axes = plt.subplots(rows,columns)\n",
    "for r in range(rows):\n",
    "    for c in range(columns):\n",
    "        image_batch = train_generator.next()\n",
    "        image = image_batch[0].astype('uint8')\n",
    "        axes[r,c].imshow(image)\n",
    "fig.set_size_inches(15,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a1c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train data\n",
    "train_images = glob.glob(\"data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4c957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5052a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Segmentation using threshol segmentation\n",
    "def crop_coords(img):\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    _, breast_mask = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)    \n",
    "    cnts, _ = cv2.findContours(breast_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt = max(cnts, key = cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    return (x, y, w, h)\n",
    "def truncation_normalization(img):\n",
    "    \n",
    "    Pmin = np.percentile(img[img!=0], 5)\n",
    "    Pmax = np.percentile(img[img!=0], 99)\n",
    "    truncated = np.clip(img,Pmin, Pmax)  \n",
    "    normalized = (truncated - Pmin)/(Pmax - Pmin)\n",
    "    normalized[img==0]=0\n",
    "    return normalized\n",
    "\n",
    "\n",
    "def clahe(img, clip):\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=clip)\n",
    "    cl = clahe.apply(np.array(img*255, dtype=np.uint8))\n",
    "    return cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad346e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(16, 8))\n",
    "axs = axs.flatten()\n",
    "images = []\n",
    "for img_path, ax in zip(train_images[:10], axs):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    (x, y, w, h) = crop_coords(img)\n",
    "    # Create a Rectangle patch\n",
    "    rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    img_cropped = img[y:y+h, x:x+w]\n",
    "    images.append(img_cropped)\n",
    "    ax.imshow(img, cmap=\"bone\")\n",
    "plt.savefig(\"rectangles.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c591b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(2, 5, figsize=(16, 8))\n",
    "axs = axs.flatten()\n",
    "final_imgs = []\n",
    "IMG_SIZE = 512\n",
    "for img_cropped, ax in zip(images, axs):\n",
    "    img_normalized = truncation_normalization(img_cropped)\n",
    "    cl1 = clahe(img_normalized, 1.0)\n",
    "    cl2 = clahe(img_normalized, 2.0)\n",
    "    img_final = cv2.merge((np.array(img_normalized*255, dtype=np.uint8),cl1,cl2))\n",
    "    img_final = cv2.resize(img_final, (IMG_SIZE, IMG_SIZE))\n",
    "    ax.imshow(img_final)\n",
    "    \n",
    "plt.savefig(\"final_imgs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Segmentation using Canny segmentation\n",
    "img = cv2.imread(r'DSC_0010.jpg')\n",
    "b,g,r = cv2.split(img)\n",
    "rgb_img = cv2.merge([r,g,b])\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "kernel = np.ones((2,2),np.uint8)\n",
    "closing = cv2.morphologyEx(thresh,cv2.MORPH_CLOSE,kernel, iterations = 2)\n",
    "sure_bg = cv2.dilate(closing,kernel,iterations=3)\n",
    "dist_transform = cv2.distanceTransform(sure_bg,cv2.DIST_L2,3)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.1*dist_transform.max(),255,0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "markers = markers+1\n",
    "markers[unknown==255] = 0\n",
    "markers = cv2.watershed(img,markers)\n",
    "img[markers == -1] = [255,0,0]\n",
    "plt.subplot(211),plt.imshow(rgb_img)\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(212),plt.imshow(thresh, 'gray')\n",
    "plt.imsave(r'thresh.png',thresh)\n",
    "plt.title(\"Otsu's binary threshold\"), plt.xticks([]), plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985af1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segmentation Model Creation\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=3,padding=\"same\",activation=\"relu\",input_shape=(50,50,1)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32,kernel_size=3,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64,kernel_size=3,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply Segmentation using instance segmentation\n",
    "ins = instanceSegmentation()\n",
    "ins.load_model(\"pointrend_resnet50.pkl\", detection_speed = \"fast\")\n",
    "ins.segmentImage(\"DSC_0010.jpg\", show_bboxes=True, output_image_name=\"output_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c170a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = instanceSegmentation()\n",
    "ins.load_model(\"pointrend_resnet50.pkl\")\n",
    "target_classes = ins.select_target_classes(person = True)\n",
    "ins.segmentImage(\"DSC_0010.jpg\", show_bboxes=True, segment_target_classes = target_classes, output_image_name=\"output_image1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a11b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = instanceSegmentation()\n",
    "ins.load_model(\"pointrend_resnet50.pkl\")\n",
    "ins.segmentImage(\"DSC_0010.jpg\", show_bboxes=True, extract_segmented_objects=True, extract_from_box = True,\n",
    "save_extracted_objects=True, output_image_name=\"output_image2.jpg\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee4174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import *\n",
    "from sklearn.metrics import *\n",
    "from tensorflow.keras.models import load_model\n",
    "input_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a9a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "buffer_size = 512\n",
    "batch_size = 16\n",
    "epochs = 2\n",
    "\n",
    "img_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read directory\n",
    "def read_directory():\n",
    "    data_filenames = []\n",
    "    data_labels = []\n",
    "\n",
    "    for filename in os.listdir(input_path + '1'):\n",
    "        data_filenames.append(input_path + '1/' + filename)\n",
    "        data_labels.append(0)\n",
    "\n",
    "    for filename in os.listdir(input_path + '2'):\n",
    "        data_filenames.append(input_path + '2/' + filename)\n",
    "        data_labels.append(1)\n",
    "\n",
    "    for filename in os.listdir(input_path + '3'):\n",
    "        data_filenames.append(input_path + '3/' + filename)\n",
    "        data_labels.append(2)\n",
    "        \n",
    "    data_size = len(data_labels)\n",
    "\n",
    "    tmp_uni = list(zip(data_filenames, data_labels))\n",
    "\n",
    "    random.shuffle(tmp_uni)\n",
    "\n",
    "    train_size = int(data_size * train_percentage)\n",
    "    print('Size of training set：', train_size)\n",
    "    print('Size of test set：', data_size - train_size)\n",
    "\n",
    "    train_list = tmp_uni[0:train_size]\n",
    "    test_list = tmp_uni[train_size:]\n",
    "\n",
    "    train_filenames, train_labels = zip(*train_list)\n",
    "    test_filenames, test_labels = zip(*test_list)\n",
    "\n",
    "    return train_filenames, train_labels, test_filenames, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_tfrecord(train_filenames, train_labels):  \n",
    "    with tf.io.TFRecordWriter(train_tfrecord)as writer:\n",
    "        for filename, label in zip(train_filenames, train_labels):\n",
    "            image = open(filename, 'rb').read()\n",
    "\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),  \n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))  \n",
    "            }\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "\n",
    "def build_test_tfrecord(test_filenames, test_labels):  \n",
    "    with tf.io.TFRecordWriter(test_tfrecord)as writer:\n",
    "        for filename, label in zip(test_filenames, test_labels):\n",
    "            image = open(filename, 'rb').read()\n",
    "\n",
    "            feature = {\n",
    "                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[image])),\n",
    "                'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "            }\n",
    "\n",
    "            example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "            writer.write(example.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7164269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_example(example_string):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "\n",
    "    feature_dict = tf.io.parse_single_example(example_string, feature_description)\n",
    "    feature_dict['image'] = tf.io.decode_png(feature_dict['image'], channels=3)\n",
    "    feature_dict['image'] = tf.image.resize(feature_dict['image'], [img_size, img_size]) / 255.0\n",
    "    return feature_dict['image'], feature_dict['label']\n",
    "\n",
    "\n",
    "def get_train_dataset(train_tfrecord):  # read TFRecord\n",
    "    raw_train_dataset = tf.data.TFRecordDataset(train_tfrecord)\n",
    "    train_dataset = raw_train_dataset.map(_parse_example)\n",
    "\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "def get_test_dataset(test_tfrecord):\n",
    "    raw_test_dataset = tf.data.TFRecordDataset(test_tfrecord)\n",
    "    test_dataset = raw_test_dataset.map(_parse_example)\n",
    "\n",
    "    return test_dataset\n",
    "\n",
    "\n",
    "def data_Preprocessing(train_dataset, test_dataset):\n",
    "    train_dataset = train_dataset.shuffle(buffer_size)\n",
    "    train_dataset = train_dataset.batch(batch_size)\n",
    "    train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    test_dataset = test_dataset.batch(batch_size)\n",
    "    test_dataset = test_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply transfer Learning using CNN\n",
    "class CNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu,\n",
    "            input_shape=(img_size, img_size, 3)\n",
    "        )\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=[5, 5],\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu\n",
    "        )\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2)\n",
    "        self.flatten = tf.keras.layers.Reshape(target_shape=(int(img_size/4) * int(img_size/4) * 64,))\n",
    "        self.dense1 = tf.keras.layers.Dense(units=512, activation=tf.nn.relu)\n",
    "        self.drop1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=3, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.drop1(x)\n",
    "        output = self.dense2(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e96c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and defing VGG16_mode\n",
    "def VGG16_model():\n",
    "    vgg16 = tf.keras.applications.VGG16(weights='imagenet',include_top=False, input_shape=[img_size,img_size,3])\n",
    "    vgg16.trainable= True\n",
    "    model = tf.keras.Sequential([\n",
    "        vgg16,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[tf.keras.metrics.sparse_categorical_accuracy]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch,lr):\n",
    "    if epoch<8:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*0.9\n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb35709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and schedule all models\n",
    "def train():\n",
    "    time_start = time.time()\n",
    "    model = VGG16_model()\n",
    "   \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    train_history = model.fit(train_dataset, epochs=epochs, callbacks=[callback])\n",
    "\n",
    "    model.save('mymodel.h5')\n",
    "    \n",
    "    print('Model saved.')\n",
    "    \n",
    "    time_end = time.time()\n",
    "    print('Training Time:', time_end - time_start)\n",
    "    print('\\n')\n",
    "\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1c732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
